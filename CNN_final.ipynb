{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e15711-11ff-44f0-883f-5d4c56d16fc1",
   "metadata": {},
   "source": [
    "## 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd46f18-44c2-4ac2-956c-9f0972e81edc",
   "metadata": {},
   "source": [
    "### 1.1 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33256b17-cfd9-4468-93f5-596c434f0a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchaudio matplotlib librosa scikit-learn pandas numpy optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16d67a9-2ce1-4bce-98f6-5e78b4023ac2",
   "metadata": {},
   "source": [
    "### 1.2 Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851dc7f3-d823-4506-931a-ec697f61d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import optuna\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8033f60e-a02c-464b-a504-fd9fe6175ecc",
   "metadata": {},
   "source": [
    "### 1.3 Set random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533596c7-6d29-4d4c-b748-a85f9d5ddbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb062d-fa5f-42e4-ab88-91766c60e2d7",
   "metadata": {},
   "source": [
    "### 1.4 Set up GPU/CPU device for PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2fc7a-0203-4b3e-aad4-26235eead1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e76fffc-3d1a-4be0-af5c-07242558af18",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03564e87-2140-4a3c-af6e-1f9c4229fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioAugmentation:\n",
    "    \"\"\"Audio data augmentation techniques for frog call detection\"\"\"\n",
    "    \n",
    "    def __init__(self, sample_rate=16000):\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def add_noise(self, waveform, noise_factor=0.005):\n",
    "        \"\"\"Add random Gaussian noise\"\"\"\n",
    "        noise = torch.randn_like(waveform) * noise_factor\n",
    "        return waveform + noise\n",
    "    \n",
    "    def time_shift(self, waveform, shift_limit=0.1):\n",
    "        \"\"\"Shift audio in time\"\"\"\n",
    "        shift = int(len(waveform) * shift_limit * (2 * torch.rand(1) - 1))\n",
    "        if shift > 0:\n",
    "            return F.pad(waveform[:-shift], (shift, 0))\n",
    "        elif shift < 0:\n",
    "            return F.pad(waveform[-shift:], (0, -shift))\n",
    "        return waveform\n",
    "    \n",
    "    def change_speed(self, waveform, speed_factor_range=(0.9, 1.1)):\n",
    "        \"\"\"Change playback speed\"\"\"\n",
    "        speed_factor = random.uniform(*speed_factor_range)\n",
    "        if speed_factor == 1.0:\n",
    "            return waveform\n",
    "        \n",
    "        # Resample to change speed\n",
    "        original_length = len(waveform)\n",
    "        new_length = int(original_length / speed_factor)\n",
    "        \n",
    "        # Simple linear interpolation for speed change\n",
    "        indices = torch.linspace(0, original_length - 1, new_length)\n",
    "        indices_floor = torch.floor(indices).long()\n",
    "        indices_ceil = torch.ceil(indices).long()\n",
    "        \n",
    "        # Clamp indices\n",
    "        indices_floor = torch.clamp(indices_floor, 0, original_length - 1)\n",
    "        indices_ceil = torch.clamp(indices_ceil, 0, original_length - 1)\n",
    "        \n",
    "        # Linear interpolation\n",
    "        alpha = indices - indices_floor.float()\n",
    "        interpolated = (1 - alpha) * waveform[indices_floor] + alpha * waveform[indices_ceil]\n",
    "        \n",
    "        # Pad or truncate to original length\n",
    "        if len(interpolated) > original_length:\n",
    "            return interpolated[:original_length]\n",
    "        else:\n",
    "            return F.pad(interpolated, (0, original_length - len(interpolated)))\n",
    "    \n",
    "    def change_volume(self, waveform, volume_range=(0.5, 1.5)):\n",
    "        \"\"\"Change volume\"\"\"\n",
    "        volume_factor = random.uniform(*volume_range)\n",
    "        return waveform * volume_factor\n",
    "    \n",
    "    def apply_augmentation(self, waveform, augment_prob=0.5):\n",
    "        \"\"\"Apply random augmentations\"\"\"\n",
    "        if random.random() < augment_prob:\n",
    "            # Apply random combination of augmentations\n",
    "            augmentations = [\n",
    "                lambda x: self.add_noise(x),\n",
    "                lambda x: self.time_shift(x),\n",
    "                lambda x: self.change_speed(x),\n",
    "                lambda x: self.change_volume(x)\n",
    "            ]\n",
    "            \n",
    "            # Randomly select 1-2 augmentations\n",
    "            selected = random.sample(augmentations, random.randint(1, 2))\n",
    "            for aug in selected:\n",
    "                waveform = aug(waveform)\n",
    "        \n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3864284-e149-42ea-8ddb-55ce82a32539",
   "metadata": {},
   "source": [
    "## 3. Audio file loading and pre-processing before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4ddc8-daad-4fc8-9f1d-2114629af4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrogCallDataset(Dataset):\n",
    "    def __init__(self, pos_dir, neg_dir, max_length=8000, augment=False, augment_prob=0.5):\n",
    "        self.max_length = max_length\n",
    "        self.augment = augment\n",
    "        self.augmenter = AudioAugmentation() if augment else None\n",
    "        self.augment_prob = augment_prob\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load positive samples (frog calls)\n",
    "        if os.path.exists(pos_dir):\n",
    "            for file in os.listdir(pos_dir):\n",
    "                if file.endswith(('.wav', '.WAV')):\n",
    "                    self.files.append(os.path.join(pos_dir, file))\n",
    "                    self.labels.append(1)\n",
    "        \n",
    "        # Load negative samples (no frog calls)\n",
    "        if os.path.exists(neg_dir):\n",
    "            for file in os.listdir(neg_dir):\n",
    "                if file.endswith(('.wav', '.WAV')):\n",
    "                    self.files.append(os.path.join(neg_dir, file))\n",
    "                    self.labels.append(0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load audio\n",
    "        wav = self.load_wav_16k_mono(self.files[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply augmentation if enabled and this is training\n",
    "        if self.augment and self.augmenter:\n",
    "            wav = self.augmenter.apply_augmentation(wav, self.augment_prob)\n",
    "        \n",
    "        # Preprocess\n",
    "        spectrogram, label = self.preprocess(wav, label)\n",
    "        return spectrogram, torch.tensor(label, dtype=torch.float32)\n",
    "    \n",
    "    def load_wav_16k_mono(self, filename):\n",
    "        \"\"\"Load a WAV file, convert it to mono and resample to 16kHz\"\"\"\n",
    "        waveform, sample_rate = torchaudio.load(filename)\n",
    "        \n",
    "        # Convert to mono if stereo\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Resample to 16kHz if needed\n",
    "        if sample_rate != 16000:\n",
    "            resampler = T.Resample(sample_rate, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        return waveform.squeeze(0)\n",
    "    \n",
    "    def preprocess(self, wav, label):\n",
    "        # Truncate or pad to max_length (0.5s = 8000 samples at 16kHz)\n",
    "        if len(wav) > self.max_length:\n",
    "            wav = wav[:self.max_length]\n",
    "        else:\n",
    "            padding = self.max_length - len(wav)\n",
    "            wav = F.pad(wav, (padding, 0), value=0.0)\n",
    "        \n",
    "        # Create spectrogram using STFT\n",
    "        stft = torch.stft(\n",
    "            wav, \n",
    "            n_fft=256,\n",
    "            hop_length=64,\n",
    "            return_complex=True\n",
    "        )\n",
    "        spectrogram = torch.abs(stft)\n",
    "        \n",
    "        # Add channel dimension\n",
    "        spectrogram = spectrogram.unsqueeze(0)\n",
    "        \n",
    "        return spectrogram, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869de59-b880-4978-b0bb-38729cc68e46",
   "metadata": {},
   "source": [
    "## 4. Deffines structure of residual blocks with skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c7a32-0f4b-4d63-b45c-3caf98975c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block for audio CNN\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e90af-000d-490e-8188-272a17828d1c",
   "metadata": {},
   "source": [
    "## 5. Deffines ARCHITECTURE FOR BINARY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336e81a-e46b-4241-9f48-a948e2435bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrogCallCNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_blocks=[2, 2, 2], dropout_rate=0.5):\n",
    "        super(FrogCallCNN, self).__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(64, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, num_blocks[2], stride=2)\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Classifier\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463c6e4-ed2f-4236-8bc5-61d3bb7069fa",
   "metadata": {},
   "source": [
    "## 6. Deffines Early stopping parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70d811-c4df-4366-826d-2bf1d6930757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        self.best_weights = model.state_dict().copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f1a43-b2a5-4c11-bad8-bf7d4706fb47",
   "metadata": {},
   "source": [
    "## 7. Deffines the training function for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e7a6e1-de98-401b-b18c-81f86ea0f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Training Function\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.001, model_type='CNN', \n",
    "                patience=10, min_delta=0.001, confidence_threshold=0.9):\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta)\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_accuracy': [], 'val_accuracy': [],\n",
    "        'train_precision': [], 'val_precision': [],\n",
    "        'train_recall': [], 'val_recall': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Training {model_type} model with early stopping...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_tp, train_fp, train_fn = 0, 0, 0\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data).squeeze()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            predicted = (outputs > confidence_threshold).float()\n",
    "            train_total += targets.size(0)\n",
    "            train_correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            train_tp += ((predicted == 1) & (targets == 1)).sum().item()\n",
    "            train_fp += ((predicted == 1) & (targets == 0)).sum().item()\n",
    "            train_fn += ((predicted == 0) & (targets == 1)).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_tp, val_fp, val_fn = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                outputs = model(data).squeeze()\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                predicted = (outputs > confidence_threshold).float()\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == targets).sum().item()\n",
    "                \n",
    "                val_tp += ((predicted == 1) & (targets == 1)).sum().item()\n",
    "                val_fp += ((predicted == 1) & (targets == 0)).sum().item()\n",
    "                val_fn += ((predicted == 0) & (targets == 1)).sum().item()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        train_precision = train_tp / (train_tp + train_fp) if (train_tp + train_fp) > 0 else 0\n",
    "        train_recall = train_tp / (train_tp + train_fn) if (train_tp + train_fn) > 0 else 0\n",
    "        train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall) if (train_precision + train_recall) > 0 else 0\n",
    "        \n",
    "        val_precision = val_tp / (val_tp + val_fp) if (val_tp + val_fp) > 0 else 0\n",
    "        val_recall = val_tp / (val_tp + val_fn) if (val_tp + val_fn) > 0 else 0\n",
    "        val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['train_accuracy'].append(train_accuracy)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        history['train_precision'].append(train_precision)\n",
    "        history['val_precision'].append(val_precision)\n",
    "        history['train_recall'].append(train_recall)\n",
    "        history['val_recall'].append(val_recall)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        print(f'  Train Acc: {train_accuracy:.2f}%, Val Acc: {val_accuracy:.2f}%')\n",
    "        print(f'  Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}')\n",
    "        print(f'  Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopping(avg_val_loss, model):\n",
    "            print(f'Early stopping triggered after epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96657496-63ec-45e0-95a1-08d9442b6fe6",
   "metadata": {},
   "source": [
    "## 8. Deffines function for hyperparameter tuning for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965eeb5-9fd7-4453-b3a9-01003c244cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(input_shape, train_loader, val_loader, n_trials=20):\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, input_shape, train_loader, val_loader), \n",
    "                  n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    print(f\"  Value: {study.best_trial.value}\")\n",
    "    print(f\"  Params: {study.best_trial.params}\")\n",
    "    \n",
    "    return study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d46b4a-608f-484b-bc84-d28432151b9a",
   "metadata": {},
   "source": [
    "## 9. Deffines objective function for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b53484-c4e7-4b90-93fd-8bbbbbc5c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, input_shape, train_loader, val_loader):\n",
    "    \"\"\"Objective function for hyperparameter optimization\"\"\"\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.7)\n",
    "    \n",
    "    model = FrogCallCNN(input_shape, dropout_rate=dropout_rate).to(device)\n",
    "    \n",
    "    # Train with suggested parameters\n",
    "    history = train_model(model, train_loader, val_loader, epochs=20, lr=lr, patience=5)\n",
    "    \n",
    "    # Return the best validation F1 score\n",
    "    return max(history['val_f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b97290-a994-4e47-b164-3c07a158c18b",
   "metadata": {},
   "source": [
    "## 10. Deffines function for graphical representations for tracking model training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919725b-0d97-4a91-b453-dd4780a72abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Loss\n",
    "    ax1.plot(history['train_loss'], 'r', label='Train Loss')\n",
    "    ax1.plot(history['val_loss'], 'b', label='Val Loss')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax2.plot(history['train_accuracy'], 'r', label='Train Accuracy')\n",
    "    ax2.plot(history['val_accuracy'], 'b', label='Val Accuracy')\n",
    "    ax2.set_title('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Precision\n",
    "    ax3.plot(history['train_precision'], 'r', label='Train Precision')\n",
    "    ax3.plot(history['val_precision'], 'b', label='Val Precision')\n",
    "    ax3.set_title('Precision')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # Recall\n",
    "    ax4.plot(history['train_recall'], 'r', label='Train Recall')\n",
    "    ax4.plot(history['val_recall'], 'b', label='Val Recall')\n",
    "    ax4.set_title('Recall')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True)\n",
    "    \n",
    "    # F1 Score\n",
    "    ax5.plot(history['train_f1'], 'r', label='Train F1')\n",
    "    ax5.plot(history['val_f1'], 'b', label='Val F1')\n",
    "    ax5.set_title('F1 Score')\n",
    "    ax5.legend()\n",
    "    ax5.grid(True)\n",
    "    \n",
    "    # Final metrics summary\n",
    "    ax6.text(0.5, 0.5, f'Final Metrics:\\nTrain Acc: {history[\"train_accuracy\"][-1]:.2f}%\\nVal Acc: {history[\"val_accuracy\"][-1]:.2f}%\\nVal F1: {history[\"val_f1\"][-1]:.4f}', \n",
    "             transform=ax6.transAxes, ha='center', va='center', fontsize=12,\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    ax6.set_title('Final Performance')\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec42ce7-12c2-4d27-9d08-2d3d6b43dc40",
   "metadata": {},
   "source": [
    "## 11. Deffines function for loading recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b6db5-ba30-4e64-8b58-f1c79ba08100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_long_audio(model, wav, window_size=8000, hop_size=4000, confidence_threshold=0.9):\n",
    "    \"\"\"Make predictions on a long audio file using sliding window with specified confidence threshold\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    confident_predictions = []\n",
    "    \n",
    "    for start in range(0, len(wav) - window_size + 1, hop_size):\n",
    "        segment = wav[start:start + window_size]\n",
    "        spectrogram = preprocess_audio_segment(segment).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(spectrogram).item()\n",
    "            predictions.append(pred)\n",
    "            # Only count as positive if above confidence threshold\n",
    "            confident_predictions.append(pred > confidence_threshold)\n",
    "    \n",
    "    return predictions, confident_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dcf183-e5e8-4801-88f6-88b22c0bcb8b",
   "metadata": {},
   "source": [
    "## 12. Deffines model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22076f-ca0d-42e9-bad0-34deb76e1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Main Execution Script\n",
    "\n",
    "def train_model(confidence_threshold=0.9):\n",
    "    # Define paths\n",
    "    POS_DIR = '/Users/jasminenelson/Library/CloudStorage/OneDrive-Personal/masters_thesis/Library/frog'\n",
    "    NEG_DIR = '/Users/jasminenelson/Library/CloudStorage/OneDrive-Personal/masters_thesis/Library/nofrog'\n",
    "   \n",
    " # Create base dataset without augmentation to get the split indices\n",
    "    print(\"Loading frog call dataset...\")\n",
    "    base_dataset = FrogCallDataset(POS_DIR, NEG_DIR, max_length=8000, augment=False)\n",
    "    \n",
    "    if len(base_dataset) == 0:\n",
    "        print(\"Warning: No audio files found. Please check your data paths.\")\n",
    "        return\n",
    "    \n",
    "    # Get input shape\n",
    "    sample_spec, _ = base_dataset[0]\n",
    "    input_shape = sample_spec.shape\n",
    "    print(f\"Spectrogram input shape: {input_shape}\")\n",
    "    \n",
    "    # Split dataset (80% train, 20% val)\n",
    "    dataset_size = len(base_dataset)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    val_size = dataset_size - train_size\n",
    "    \n",
    "    # Get the split indices\n",
    "    train_indices, val_indices = torch.utils.data.random_split(range(dataset_size), [train_size, val_size])\n",
    "    \n",
    "    # Create separate datasets for training (with augmentation) and validation (without)\n",
    "    train_dataset = FrogCallDataset(POS_DIR, NEG_DIR, max_length=8000, augment=True, augment_prob=0.6)\n",
    "    val_dataset = FrogCallDataset(POS_DIR, NEG_DIR, max_length=8000, augment=False)\n",
    "    \n",
    "    # Create subset datasets using the indices\n",
    "    train_subset = torch.utils.data.Subset(train_dataset, train_indices.indices)\n",
    "    val_subset = torch.utils.data.Subset(val_dataset, val_indices.indices)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    print(f\"Training samples: {len(train_subset)}\")\n",
    "    print(f\"Validation samples: {len(val_subset)}\")\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    print(\"\\nHyperparameter tuning\")\n",
    "    best_params = hyperparameter_tuning(input_shape, train_loader, val_loader, n_trials=10)\n",
    "    \n",
    "    # Create and train model\n",
    "    if best_params:\n",
    "        print(f\"Using optimized parameters: {best_params}\")\n",
    "        model = FrogCallCNN(\n",
    "            input_shape, \n",
    "            dropout_rate=best_params.get('dropout_rate', 0.5)\n",
    "        ).to(device)\n",
    "        lr = best_params.get('lr', 0.001)\n",
    "    else:\n",
    "        print(\"Using default parameters...\")\n",
    "        model = FrogCallCNN(input_shape, dropout_rate=0.5).to(device)\n",
    "        lr = 0.001\n",
    "    \n",
    "    print(f\"\\nModel architecture:\")\n",
    "    print(model)\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Train model with 90% confidence threshold\n",
    "    print(f\"\\nTraining ResNet model with {confidence_threshold*100}% confidence threshold...\")\n",
    "    history = train_model(model, train_loader, val_loader, epochs=100, lr=lr, \n",
    "                         patience=15, confidence_threshold=confidence_threshold)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'frog_call_cnn_final.pth')\n",
    "    print(\"ANALYSIS COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef218ee-87dd-4a12-bb14-cb35f59b9c55",
   "metadata": {},
   "source": [
    "## 13. Defines function to apply model to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6122f9-2301-4ee0-be67-16c200ee3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_site(confidence_threshold=0.9):\n",
    "\n",
    "    excel_file_path = '/Users/jasminenelson/Library/CloudStorage/OneDrive-Personal/masters_thesis/site_files/Excel/Turmalina_24_F/Turmalina_2024_021.xlsx'\n",
    "   \n",
    "    input_shape = (1, 129, 125)\n",
    "    \n",
    "    # Load model\n",
    "    model = FrogCallCNN(input_shape=input_shape, dropout_rate=0.5).to(device)\n",
    "    model.load_state_dict(torch.load('frog_call_cnn_final.pth', map_location=device))\n",
    "    model.eval()\n",
    "    print(f\"\\nTesting model with {confidence_threshold*100}% confidence threshold...\")\n",
    "    \n",
    "    # Read the Excel file\n",
    "    try:\n",
    "        df = pd.read_excel(excel_file_path)\n",
    "        print(f\"Loaded Excel file: {excel_file_path}\")\n",
    "        print(f\"Found {len(df)} files to process\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize result columns\n",
    "    df['frog_calls'] = None\n",
    "    df['avg_confidence'] = None\n",
    "    df['max_confidence'] = None\n",
    "    df['total_segments'] = None\n",
    "    df['high_confidence_segments'] = None\n",
    "    df['percentage_with_frogs'] = None\n",
    "    df['confidence_threshold'] = confidence_threshold\n",
    "    \n",
    "    processed_count = 0\n",
    "    successful_count = 0\n",
    "    \n",
    "    # Process each file in the Excel sheet\n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['filename']\n",
    "        file_path = row['file_path']\n",
    "        \n",
    "        print(f\"Processing {filename}...\")\n",
    "        processed_count += 1\n",
    "        \n",
    "        # Construct full file path\n",
    "        full_path = file_path\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(full_path):\n",
    "            print(f\"  File not found: {full_path}\")\n",
    "            df.at[index, 'frog_calls'] = 'File Not Found'\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load audio file\n",
    "            wav = load_mp3_16k_mono(full_path)\n",
    "            \n",
    "            if wav is not None:\n",
    "                predictions, confident_predictions = predict_on_long_audio(\n",
    "                    model, wav, confidence_threshold=confidence_threshold\n",
    "                )\n",
    "                \n",
    "                if predictions:\n",
    "                    # Calculate statistics\n",
    "                    avg_confidence = np.mean(predictions)\n",
    "                    max_confidence = np.max(predictions)\n",
    "                    total_segments = len(predictions)\n",
    "                    \n",
    "                    # Determine if frog calls are present\n",
    "                    frog_present = any(confident_predictions)\n",
    "                    frog_calls = \"Present\" if frog_present else \"Absent\"\n",
    "                    \n",
    "                    # Count segments with high confidence frog calls\n",
    "                    high_confidence_segments = sum(confident_predictions)\n",
    "                    percentage_with_frogs = (high_confidence_segments / total_segments) * 100\n",
    "                    \n",
    "                    # Add results to dataframe\n",
    "                    df.at[index, 'frog_calls'] = frog_calls\n",
    "                    df.at[index, 'avg_confidence'] = round(avg_confidence, 4)\n",
    "                    df.at[index, 'max_confidence'] = round(max_confidence, 4)\n",
    "                    df.at[index, 'total_segments'] = total_segments\n",
    "                    df.at[index, 'high_confidence_segments'] = high_confidence_segments\n",
    "                    df.at[index, 'percentage_with_frogs'] = round(percentage_with_frogs, 2)\n",
    "                    \n",
    "                    successful_count += 1\n",
    "                    print(f\"  {filename}: {frog_calls} (avg={avg_confidence:.3f}, max={max_confidence:.3f}, {high_confidence_segments}/{total_segments} segments)\")\n",
    "                else:\n",
    "                    print(f\"  Could not process {filename} - no predictions generated\")\n",
    "                    df.at[index, 'frog_calls'] = 'Processing Error'\n",
    "            else:\n",
    "                print(f\"  Could not load {filename}\")\n",
    "                df.at[index, 'frog_calls'] = 'Load Error'\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {filename}: {e}\")\n",
    "            df.at[index, 'frog_calls'] = f'Error: {str(e)}'\n",
    "    \n",
    "    # Save the updated Excel file\n",
    "    try:\n",
    "        # Create output filename with threshold info\n",
    "        base_name = os.path.splitext(excel_file_path)[0]\n",
    "        output_file = f\"{base_name}_results_aug_{int(confidence_threshold*100)}pct2.xlsx\"\n",
    "        \n",
    "        df.to_excel(output_file, index=False)\n",
    "        print(f\"\\nResults saved to: {output_file}\")\n",
    "        \n",
    "        # Also save a backup of the original with results\n",
    "        backup_file = f\"{base_name}_results2_aug.xlsx\"\n",
    "        df.to_excel(backup_file, index=False)\n",
    "        print(f\"Backup saved to: {backup_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Excel file: {e}\")\n",
    "        # Fallback to CSV if Excel save fails\n",
    "        csv_file = f\"{base_name}_results_{int(confidence_threshold*100)}pct.csv\"\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"Results saved as CSV: {csv_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nSummary with {confidence_threshold*100}% confidence threshold:\")\n",
    "    print(f\"Files processed: {processed_count}\")\n",
    "    print(f\"Files successfully analyzed: {successful_count}\")\n",
    "    \n",
    "    if successful_count > 0:\n",
    "        files_with_frogs = len(df[df['frog_calls'] == 'Present'])\n",
    "        detection_rate = (files_with_frogs / successful_count) * 100\n",
    "        print(f\"Files with frog calls detected: {files_with_frogs}\")\n",
    "        print(f\"Detection rate: {detection_rate:.1f}%\")\n",
    "        \n",
    "        # Show some statistics\n",
    "        valid_results = df[df['frog_calls'].isin(['Present', 'Absent'])]\n",
    "        if len(valid_results) > 0:\n",
    "            print(f\"\\nConfidence Statistics:\")\n",
    "            print(f\"Average confidence across all files: {valid_results['avg_confidence'].mean():.3f}\")\n",
    "            print(f\"Maximum confidence found: {valid_results['max_confidence'].max():.3f}\")\n",
    "            print(f\"Average percentage with frogs: {valid_results['percentage_with_frogs'].mean():.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f81aa-d046-4699-b0b4-a5435949d9ab",
   "metadata": {},
   "source": [
    "## 14. Run model training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a1679-6a0e-4937-9316-46733fc7810e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24ce95-b3f1-4ef1-bcaa-d8efbb0b95ea",
   "metadata": {},
   "source": [
    "## 15. Run trained model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff56df-bbd9-4d10-9e60-3ef38947be49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_site()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
